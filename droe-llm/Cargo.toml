[package]
name = "droe-llm"
version = "0.1.0"
edition = "2021"
description = "Centralized LLM service for DROELANG - Adaptive AI for robotics and development"
license = "MIT"
authors = ["DROELANG Team"]

[lints]
workspace = true

[[bin]]
name = "droe-llm"
path = "src/main.rs"

[[example]]
name = "test_grpc_wrapper"
path = "examples/test_grpc_wrapper.rs"
required-features = ["grpc"]

[lib]
name = "droe_llm"
path = "src/lib.rs"

[dependencies]
# Core async runtime
tokio = { version = "1.0", features = ["full"] }
tokio-stream = "0.1"
tokio-util = "0.7"
async-stream = "0.3"
futures = "0.3"

# gRPC framework (deprecated - keeping for backward compatibility)
tonic = { version = "0.10", optional = true }
prost = { version = "0.12", optional = true }

# HTTP client for Ollama
reqwest = { version = "0.11", features = ["json", "stream"] }

# Serialization
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"

# Utilities
anyhow = "1.0"
thiserror = "1.0"
uuid = { version = "1.0", features = ["v4"] }
bytes = "1.0"
regex = "1.0"

# Configuration
config = "0.14"

# Logging
tracing = "0.1"
tracing-subscriber = "0.3"

# CLI
clap = { version = "4.0", features = ["derive"] }

[build-dependencies]
tonic-build = { version = "0.10", optional = true }

[features]
default = ["ollama", "jsonrpc", "grpc"]
ollama = []
openai = []
anthropic = []
grpc = ["tonic", "prost", "tonic-build"]
jsonrpc = []

